{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime,timedelta\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#根据log_index，增量读取log内容\n",
    "def load_log(file_name, log_index):\n",
    "    log_value_list = list()\n",
    "    date_list = list()\n",
    "    status_list = list()\n",
    "    try:\n",
    "        with open(file_name,'rb') as f:\n",
    "            for index,content in enumerate(f):\n",
    "                if index == log_index:\n",
    "                    try:\n",
    "                        log_data = json.loads(content.decode('utf8'))\n",
    "                    except Exception as e:\n",
    "                        print ('json解析错误',index,content[:50])\n",
    "                        log_index += 1\n",
    "                        continue\n",
    "                        \n",
    "                    if '@timestamp' in log_data:\n",
    "                        log_data['@timestamp'] = str(datetime.strptime(log_data['@timestamp'][0:19],'%Y-%m-%dT%H:%M:%S'))\n",
    "                        log_value_list.append(log_data)\n",
    "                        date_list.append(log_data['@timestamp'])\n",
    "                        if log_data['status'] not in status_list:\n",
    "                            status_list.append(log_data['status'])\n",
    "                    log_index += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print('其他错误',index,e)\n",
    "    #将文本内容转化为pandas的dataframe\n",
    "    #temp_log = pd.DataFrame(log_value_list)\n",
    "    print(status_list)\n",
    "    return  log_value_list,log_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_urls_in_op = 20 #关键参数，每x个url作为一组进行分配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json解析错误 188583 b'{\"clientip\":\"218.56.245.25\",\"@timestamp\":\"2017-07-'\n",
      "json解析错误 188584 b'{\"clientip\":\"218.56.245.25\",\"@tLw52EroRdeH103qIDaN'\n",
      "json解析错误 188585 b'{\"clientip\":\"60.209.50.36\",\"@timestamp\":\"2017-07-1'\n",
      "json解析错误 188586 b'{\"clil2sH7h19ruZvCdczFuktGr2VZd\"/1.1\",D08/r9tJ51+G'\n",
      "json解析错误 188587 b'{\"clil2sH7h19ruZvCdczFuktGr2VZd\"/1.1\",D08/r9tJ51+G'\n",
      "json解析错误 188588 b'{\"clientip\":\"218.56.245.25\",\"@33Tf31y9Ketice.do?ty'\n",
      "json解析错误 188589 b'{\"clientip\":\"218.56.245.25\",\"@33Tf31y9Ketice.jwvpY'\n",
      "json解析错误 188590 b'{\"clientip\":\"203.2c50a77d180abf3542ea01a92ad65659b'\n",
      "json解析错误 188591 b'{\"clientiplipa23305\",\"s1, 11.234.75.req_titor/ini0'\n",
      "json解析错误 188592 b'{\"clientiplipa23305\",\"s1, 11.234.75.req_titor/ini0'\n",
      "json解析错误 188593 b'{\"clientip\":\"60.209.50.36\",\"@timalipay\"clientiplip'\n",
      "json解析错误 188594 b'{vO8\"s,\"s883pital.alipay-eco36\"}\\n'\n",
      "json解析错误 188595 b'medical883prod/loginByAlipay?app_id ups6070701589k'\n",
      "json解析错误 188596 b'medical883prod&auth_\",\"urf0b4b5bce81d45a4ae6b2f5ec'\n",
      "json解析错误 188597 b'medical883prod/883/pY-Se_883_info?883\":\"ht49554084'\n",
      "json解析错误 188598 b'{\"clientip\":\"203.209.234.143\",\"@talipay\"clientipli'\n",
      "json解析错误 188599 b'{\"clientip\":\"60.209.50.36\",\"@timalipay\"clientip39.'\n",
      "json解析错误 188600 b'{\"clientip\":\"60.209.50.36\",\"@timestamp\":\"2017-31ef'\n",
      "json解析错误 188601 b'{\"clientip\":\"203.209.234.143\",\"@talipay\"clientip39'\n",
      "json解析错误 188602 b'{\"clientip\":\"60.209.5user9.50.36\",\"argetUrl=\"20880'\n",
      "json解析错误 188603 b'{\"clientip\":\"203.209.234.143\",\"@talipay\"clientip39'\n",
      "json解析错误 188604 b'{\"clientip\"user9.50.36\",\"argetUrl=\"208800014440&\":'\n",
      "['200', '302', '403', '500', '504', '404', '304', '206']\n"
     ]
    }
   ],
   "source": [
    "time_step = 120 #每x秒读取一次log文件\n",
    "time_windows = 120 #秒,时间窗口\n",
    "ip_dict = dict() #ip与对应操作在矩阵的下标\n",
    "ip_reserve_list = list() #操作矩阵下标对应的ip\n",
    "all_matrix = np.empty([0, 6],dtype=int)  #操作矩阵\n",
    "all_log = pd.DataFrame() #所有的日志数据\n",
    "temp_log_data = pd.DataFrame() #某时间范围的日志数据\n",
    "all_url_list = list()\n",
    "time_index = '2017-07-13 06:25:08' #记录当前的时间\n",
    "log_index = 0 #记录读到第几行了\n",
    "ip_behavior_dict = dict() #记录每个ip每分钟请求的页面url\n",
    "\n",
    "increment_log_data, log_index = load_log('data/access_szy_shunnengnet_com_json.log', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188583"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(increment_log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#截取url，保留其访问传参方式（POST/GET/PUT/DELETE）,保留url的头与尾\n",
    "def deal_url(url):\n",
    "    url_str = url.replace(' HTTP/1.1','')\n",
    "    if url_str.find(' ') > -1:\n",
    "        url_type = url_str[0 : url_str.find(' ')+1]\n",
    "    if url_str.find('/') > -1 and url_str.find('?') > -1:\n",
    "        url_str = url_type + url_str[url_str.find('/')+1 : url_str.find('?')]\n",
    "    if url_str.find('/') > -1 and url_str.find(';jsessionid') > -1:\n",
    "        url_str = url_type + url_str[url_str.find('/')+1 : url_str.find(';jsessionid')]\n",
    "    if url_str.find('/') > -1 and url_str.rfind('/') > -1:\n",
    "        url_str = url_str[0 : url_str.find('/')] + '/.../' + url_str[url_str.rfind('/')+1 : ]\n",
    "    return url_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#根据日志内容，创建一个信息的op_detail\n",
    "def create_op_detail(row_log):\n",
    "    op_detail = dict()\n",
    "    op_detail['start_time'] = row_log['@timestamp']\n",
    "    op_detail['end_time'] = row_log['@timestamp']\n",
    "    op_detail['urls'] = list()\n",
    "    op_detail['urls'].append(deal_url(row_log['request']))\n",
    "    return op_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#传入开始结束时间的字符串(yyyy-MM-dd HH:mm:ss)，计算时间差并返回时差(秒)\n",
    "def cacl_time_difference(start_time_str, end_time_str):\n",
    "    start_time = datetime.strptime(start_time_str,'%Y-%m-%d %H:%M:%S')\n",
    "    end_time = datetime.strptime(end_time_str,'%Y-%m-%d %H:%M:%S')\n",
    "    return int((end_time - start_time).seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#读取log，生成携带用户行为的复合型字典\n",
    "def create_user_behavior_dict(increment_log_data, user_behavior_dict):\n",
    "    \n",
    "    for x in increment_log_data:\n",
    "        if x['sip'] != '':\n",
    "            \n",
    "            if x['sip'] not in user_behavior_dict.keys():\n",
    "                user_behavior_dict[x['sip']] = list()\n",
    "\n",
    "            if len(user_behavior_dict[x['sip']]) == 0: #opreation内没有op_detail,则创建op_detail\n",
    "                user_behavior_dict[x['sip']].append(create_op_detail(x))\n",
    "            else: #opreation内已存在op_detail，此时需要循环该list的所有dict，找到未填充满num_urls_in_op的记录\n",
    "                new_opreation = 1\n",
    "                i = 0\n",
    "                for op_detail in user_behavior_dict[x['sip']]:\n",
    "                    if len(op_detail['urls']) < num_urls_in_op:\n",
    "                        op_detail['end_time'] = x['@timestamp']\n",
    "                        op_detail['urls'].append(deal_url(x['request']))\n",
    "                        new_opreation = 0\n",
    "                        break\n",
    "                if new_opreation == 1:\n",
    "                    user_behavior_dict[x['sip']].append(create_op_detail(x))\n",
    "                    i += 1\n",
    "                    \n",
    "                \n",
    "    return user_behavior_dict\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_behavior_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "user_behavior_dict = create_user_behavior_dict(increment_log_data, user_behavior_dict)\n",
    "end_time = datetime.now()\n",
    "print((end_time - start_time).seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "c = 1\n",
    "for x in increment_log_data:\n",
    "    if x['sip'] == '':\n",
    "        print (c)\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188565"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "for ip in user_behavior_dict:\n",
    "    for op in user_behavior_dict[ip]:\n",
    "        sum += len(op['urls'])\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #定义模板list\n",
    "# templates = list()\n",
    "# templates.append(['GET /common/.../notice.do','POST /common/.../chooseHospital.do','GET /common/.../chooseExpert.do','GET /common/.../deptList.do','POST /.../getDept.do','GET /common/.../scheduleByDept.do','POST /.../scheduleByDept.do','GET /common/.../arrangementList.do','POST /.../getTimeList.do','GET /common/.../reserveConfirm.do','POST /.../reserveConfirm.do','POST /.../reserve.do']) #普通专家预约\n",
    "# templates.append(['GET /common/.../notice.do','POST /common/.../chooseHospital.do','GET /common/.../chooseExpert.do','GET /common/.../expertNotice.do','POST /common/.../deptList.do','POST /.../getDept.do','GET /common/.../scheduleByDept.do','POST /.../scheduleByDept.do','GET /common/.../arrangementList.do','POST /.../getTimeList.do','GET /common/.../reserveConfirm.do','POST /.../reserveConfirm.do','POST /.../reserve.do'])#知名专家预约\n",
    "# templates.append(['GET /common/.../notice.do','POST /common/.../chooseHospital.do','GET /common/.../chooseExpert.do','GET /common/.../specialClinic.do','POST /.../getDepts.do','GET /common/.../specialSchedule.do','POST /.../specialSchedule.do','GET /common/.../arrangementList.do','POST /.../getTimeList.do','GET /common/.../reserveConfirm.do','POST /.../reserveConfirm.do','POST /.../reserve.do'])#特色门诊预约\n",
    "# templates.append(['GET /common/.../patientinfo.do','GET /common/.../reserveList.do','POST /.../getReserveList.do','GET /common/.../reserveDetail.do','POST /.../cancelReserve.do'])#取消预约\n",
    "# templates.append(['GET /common/.../patientinfo.do','GET /common/.../patientMgr.do ','GET /.../patientinfo.do','GET /common/.../addPatient.do','POST /.../checkIdCard.do','POST /.../create.do'])#新增就诊人\n",
    "# templates.append(['GET /common/.../patientinfo.do','GET /common/.../patientMgr.do ','GET /common/.../editPatient.do','POST /.../getPatientInfoById.do','POST /.../setDefault.do',''])#设置默认就诊人\n",
    "# templates.append(['GET /common/.../patientinfo.do','GET /common/.../patientMgr.do ','GET /common/.../editPatient.do','POST /.../getPatientInfoById.do','GET /common/.../bind.do','POST /.../bindHosCard.do'])#绑卡\n",
    "# templates.append(['GET /common/.../patientinfo.do','GET /common/.../patientMgr.do ','GET /common/.../editPatient.do','POST /.../getPatientInfoById.do','GET /.../deletePatient.do'])#删除就诊人\n",
    "# templates.append(['GET /.../init.do','GET /common/.../reportType.do ','GET /common/.../reportList.do','GET /.../getReportList.do','GET /common/.../reportDetail.do','GET /.../getReportDeatil.do'])#门诊报告\n",
    "# templates.append(['GET /.../init.do','GET /common/.../reportType.do ','GET /common/.../reportList.do','GET /.../getReportInList.do','GET /.../getReportDeatil.do'])#住院报告\n",
    "# templates.append(['GET /.../init.do','GET /common/.../index.do','GET /common/.../balance.do','GET /.../patientBalance.do'])#门诊预交金\n",
    "# templates.append(['GET /.../init.do','GET /common/.../index.do','GET /common/.../hosBalance.do','POST /.../inBalance.do'])#住院预交金\n",
    "# templates.append(['GET /.../init.do','GET /common/.../index.do','GET /common/.../outpFeeList.do','POST /.../feeList.do','GET /common/.../feeDetail.do','POST /.../feeDetail.do'])#门诊费用\n",
    "# templates.append(['GET /.../init.do','GET /common/.../index.do','GET /common/.../inpFeeList.do','POST /.../feeList.do','GET /common/.../feeDetail.do','POST /.../feeDetail.do'])#住院费用\n",
    "# templates.append(['GET /.../init.do','GET /common/.../reserveQueueList.do','POST /.../getQueueList.do'])#候诊队列\n",
    "# templates.append(['POST coreServlet'])#处理微信发送来的数据\n",
    "# templates.append(['GET common/.../arrangementList.do', 'GET /.../404.do','POST /.../getTimeList.do'])#异常模板1\n",
    "# #templates.append(['POST /.../getTimeList.do','POST /.../getTimeList.do','GET common/.../arrangementList.do','GET /.../404.do','GET common/.../arrangementList.do','GET /.../404.do'])#异常模板1\n",
    "# templates.append(['GET common/.../scheduleByDept.do','POST /.../scheduleByDept.do','POST /.../getTimeList.do','GET common/.../arrangementList.do','POST /.../getTimeList.do', 'POST /.../getTimeList.do','POST /.../getTimeList.do','POST /.../getTimeList.do', 'POST /.../getTimeList.do'])#异常模板2\n",
    "# #templates.append(['GET common/.../arrangementList.do', 'GET common/.../arrangementList.do', 'GET common/.../arrangementList.do', 'POST /.../getTimeList.do', 'POST /.../getTimeList.do', 'POST /.../getTimeList.do', 'POST /.../getTimeList.do', 'POST /.../getTimeList.do', 'POST /.../getTimeList.do', 'POST /.../getTimeList.do', 'POST /.../getTimeList.do', 'POST /.../getTimeList.do'])#异常模板3\n",
    "# templates.append(['GET /common/.../deptList.do','POST /.../getDept.do','GET /common/.../scheduleByDept.do','POST /.../scheduleByDept.do','GET /common/.../arrangementList.do','POST /.../getTimeList.do'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# probability_dict = dict()\n",
    "\n",
    "# for x in user_behavior_dict.keys():\n",
    "#     for op_detail in user_behavior_dict[x]:\n",
    "#         matched_operations = np.zeros(len(templates),dtype='float32')\n",
    "#         for idx,template in enumerate(templates):\n",
    "#             n_template = len(template)\n",
    "#             count = 0\n",
    "#             probability_count = 0\n",
    "#             for str in template:\n",
    "#                 if str in op_detail['urls']:\n",
    "#                     probability_count += 1\n",
    "#             for url in op_detail['urls']:\n",
    "#                 if url in template:\n",
    "#                     count += 1\n",
    "#             n_op = max(len(op_detail['urls']),16)\n",
    "#             matched_operations[idx] = (probability_count / n_template) * (count / n_op)\n",
    "#         if x not in probability_dict.keys():\n",
    "#             probability_dict[x] = matched_operations.reshape([1,19])\n",
    "#         else:\n",
    "#             probability_dict[x] = np.vstack((probability_dict[x],matched_operations))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13385"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "for x in user_behavior_dict.keys():\n",
    "    idx += len(user_behavior_dict[x])\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "#速度变慢的罪魁祸首\n",
    "def judge_time_range(start_time_str, end_time_str, time_str):\n",
    "    start_date = time.strptime(start_time_str,'%Y-%m-%d %H:%M:%S')\n",
    "    end_date = time.strptime(end_time_str,'%Y-%m-%d %H:%M:%S')\n",
    "    time_date = time.strptime(time_str,'%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    if time_date > start_date and time_date < end_date:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!!!生成出现过的ip列表unique_dict\n",
    "#为每一个ip计算他访问过多少唯一页面，占访问次数的比例。frequency这英文似乎给错了，不是频率，而是覆盖率coverage \n",
    "\n",
    "\n",
    "unique_dict = dict()\n",
    "for x in increment_log_data:\n",
    "    ip = x['sip']\n",
    "    if ip not in unique_dict.keys():\n",
    "        unique_dict[ip] = dict()\n",
    "        unique_dict[ip]['coverage'] = 0\n",
    "        unique_dict[ip]['urls'] = list()\n",
    "    url = deal_url(x['request'])\n",
    "    unique_dict[ip]['urls'].append(url)\n",
    "    \n",
    "for ip in unique_dict.keys():\n",
    "    unique_list = list()\n",
    "    for url in unique_dict[ip]['urls']:\n",
    "        if url not in unique_list:\n",
    "            unique_list.append(url)\n",
    "    #print(len(unique_dict[ip]['urls']))\n",
    "    unique_dict[ip]['coverage'] = len(unique_list) / len(unique_dict[ip]['urls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_operation_label(ip, time):\n",
    "#     global probability_dict\n",
    "#     class_type = 0\n",
    "#     for x in user_behavior_dict:\n",
    "#         if x == ip:\n",
    "#             index = 0\n",
    "#             for op_detail in user_behavior_dict[x]:\n",
    "#                 start_str = op_detail['start_time']\n",
    "#                 end_str = op_detail['end_time']\n",
    "#                 if judge_time_range(start_str, end_str, time):\n",
    "#                     class_type = probability_dict[ip][:,16:].sum()\n",
    "#                     #if probability_dict[ip][:,16:].sum() > 1:\n",
    "#                         #class_type = 1\n",
    "#                     #elif probability_dict[ip][index,17] > 0.4:\n",
    "#                         #class_type = 1\n",
    "#                    # elif probability_dict[ip][index,18] > 0.4:\n",
    "#                         #class_type = 1\n",
    "#                     break #如果匹配到了，也给了class_type了，还继续循环干什么\n",
    "#                 else:\n",
    "#                     index += 1\n",
    "#     return class_type\n",
    "\n",
    "\n",
    "# def get_operation_label(ip):\n",
    "#     global unique_dict\n",
    "#     class_type = 0\n",
    "#     if unique_dict[ip]['coverage'] < 0.1:\n",
    "#         class_type = 1\n",
    "#     return class_type\n",
    "\n",
    "import json\n",
    "with open('label_json.txt', 'r') as f:\n",
    "    labels_dict = json.loads(f.read())\n",
    "def get_operation_label(ip):\n",
    "    global labels_dict\n",
    "    return labels_dict[ip]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08907346412716598"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exception_ip_list = list()\n",
    "for x in unique_dict.keys():\n",
    "    if unique_dict[x]['coverage'] < 0.15:\n",
    "        exception_ip_list.append(x)\n",
    "len(exception_ip_list)/len(unique_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_operation_label('112.224.2.20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----------------------start\n",
    "class IPAccessInfo(object):\n",
    "    def __init__(self, all_url_list, all_url_dict_list):\n",
    "        self.all_url_list = all_url_list\n",
    "        self.all_url_dict_list = all_url_dict_list\n",
    "        \n",
    "import pickle\n",
    "fp = open('data/url_info.pkl','rb',True)\n",
    "iPAccessInfo = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Embedding\n",
    "\n",
    "# #列出唯一的url\n",
    "# url_dict = dict()\n",
    "# for urls in iPAccessInfo.all_url_list:\n",
    "#     for url in urls:\n",
    "#         if url not in url_dict.keys():\n",
    "#             url_dict[url] = 1\n",
    "#         else:\n",
    "#             url_dict[url] = url_dict[url] + 1\n",
    "            \n",
    "# url_list = list(url_dict.keys())\n",
    "\n",
    "# #将url embedding，转为固定长度的向量\n",
    "# num_urls = len(url_list)\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(num_urls, 32, input_length=1))\n",
    "# model.compile('rmsprop', 'mse')\n",
    "\n",
    "# input_array = np.array(range(num_urls))   #生成一个[num_url,1]的矩阵\n",
    "# output_array = model.predict(input_array)\n",
    "# print (output_array.shape)\n",
    "# print (output_array)\n",
    "\n",
    "# # 建立url_dict备查\n",
    "# url_dict = dict()\n",
    "# idx = 0\n",
    "# for url in url_list:\n",
    "#     url_dict[url] = output_array[idx,0,:]\n",
    "#     idx = idx + 1\n",
    "\n",
    "\n",
    "import pickle\n",
    "fp = open('url_embedding.pkl','rb',True)\n",
    "url_dict = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#老版本数据转换，将按照时间窗口、ip进行归类的urls列表，转化为时序data\n",
    "# def operations_to_sequence(all_url_dict_list):\n",
    "#     operation_matrix = np.zeros((len(all_url_dict_list),20,32))\n",
    "#     ip_operation_index = 0\n",
    "#     for ip_operations in all_url_dict_list: #对于每小段窗口，以ip归类的urls集合\n",
    "#         ip_operation_url_index = 0\n",
    "#         for url in ip_operations['urls']: #如果是dict字典的话\n",
    "#             url_vector = url_dict[url]\n",
    "#             operation_matrix[ip_operation_index, ip_operation_url_index, :] = url_vector\n",
    "#             ip_operation_url_index = ip_operation_url_index + 1\n",
    "#             if ip_operation_url_index>=20:  #不超过20个长度的序列，可以改\n",
    "#                 break\n",
    "#         ip_operation_index = ip_operation_index + 1\n",
    "#     return operation_matrix\n",
    "\n",
    "\n",
    "#新版本数据转换，将按照ip地址，然后里面的几段行为数据，转化为时序data\n",
    "# 数据格式为：\n",
    "# {'223.104.186.241': [{'end_time': '2017-07-13 06:25:32',\n",
    "#    'start_time': '2017-07-13 06:25:02',\n",
    "#    'urls': ['POST /.../getDept.do',\n",
    "#     'POST /.../getDept.do',\n",
    "#     'GET common/.../scheduleByDept.do',\n",
    "#     'POST /.../scheduleByDept.do',\n",
    "#     'GET common/.../arrangementList.do',\n",
    "#     'GET common/.../arrangementList.do',\n",
    "#     'POST /.../getTimeList.do',\n",
    "#     'GET common/.../reserveConfirm.do',\n",
    "#     'POST /.../reserveConfirm.do',\n",
    "#     'GET common/.../patientList.do',\n",
    "#     'GET /.../patientinfo.do',\n",
    "#     'GET common/.../reserveConfirm.do',\n",
    "#     'POST /.../reserveConfirm.do',\n",
    "#     'POST /.../reserve.do']},\n",
    "#   {'end_time': '2017-07-13 07:31:18',\n",
    "#    'start_time': '2017-07-13 07:26:36',\n",
    "#    'urls': ['GET /.../noticePage.html',\n",
    "\n",
    "def operations_to_sequence(user_behavior_dict):\n",
    "    #计算这个dict中有多少段操作\n",
    "    n_op_details = 0\n",
    "    for x in user_behavior_dict.keys():\n",
    "        n_op_details += len(user_behavior_dict[x])\n",
    "    \n",
    "    operation_matrix = np.zeros((n_op_details,num_urls_in_op,32))\n",
    "    ip_operation_index = 0\n",
    "    for ip in user_behavior_dict.keys(): #对于每个ip,得到op_detail列表\n",
    "        for op_detail in user_behavior_dict[ip]: #对于每一组urls操作\n",
    "            ip_operation_url_index = 0\n",
    "            for url in op_detail['urls']: #对于每一个url\n",
    "                url_vector = url_dict[url]  #翻译为url对应的vector\n",
    "                operation_matrix[ip_operation_index, ip_operation_url_index, :] = url_vector\n",
    "                ip_operation_url_index += 1\n",
    "                if ip_operation_url_index>=num_urls_in_op:  #不超过20个长度的序列，可以改\n",
    "                    break\n",
    "            ip_operation_index += 1\n",
    "    return operation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_url_list_count = dict() #计算一下每一个url出现的次数，url:count\n",
    "for x in increment_log_data:\n",
    "    ip = deal_url(x['request'])\n",
    "    if ip not in unique_url_list_count:\n",
    "        unique_url_list_count[ip] = 0\n",
    "    unique_url_list_count[ip] +=1\n",
    "\n",
    "#生成访问记录所有url的list，唯一，只有大于20的url才被认为具有普遍性\n",
    "unique_url_list = [x for x in unique_url_list_count.keys() if unique_url_list_count[x] > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GET /.../': 347,\n",
       " 'GET /.../coreServlet': 1,\n",
       " 'GET /.../error303.png': 45,\n",
       " 'GET /.../favicon.ico': 218,\n",
       " 'GET /.../font_1447920314_865217.css': 1,\n",
       " 'GET /.../index_network.html': 936,\n",
       " 'GET /.../robots.txt': 1,\n",
       " 'GET SN-SZY-Server/.../bindByAlipay.do': 32,\n",
       " 'GET SN-SZY-Server/.../bindByNet.do': 17,\n",
       " 'GET SN-SZY-Server/.../bindByWechat.do': 1167,\n",
       " 'GET SN-SZY-Server/.../bindNotice.do': 358,\n",
       " 'GET SN-SZY-Server/.../cancelRegister.do': 3,\n",
       " 'GET SN-SZY-Server/.../checkDetail.do': 42,\n",
       " 'GET SN-SZY-Server/.../checkList.do': 898,\n",
       " 'GET SN-SZY-Server/.../delete.do': 2,\n",
       " 'GET SN-SZY-Server/.../eastDept.do': 8551,\n",
       " 'GET SN-SZY-Server/.../examineDetail.do': 2420,\n",
       " 'GET SN-SZY-Server/.../examineList.do': 5180,\n",
       " 'GET SN-SZY-Server/.../feeNotice.html': 123,\n",
       " 'GET SN-SZY-Server/.../getRegResource.do': 21760,\n",
       " 'GET SN-SZY-Server/.../head.html': 203,\n",
       " 'GET SN-SZY-Server/.../inFeeDetail.do': 954,\n",
       " 'GET SN-SZY-Server/.../inFeeList.do': 1371,\n",
       " 'GET SN-SZY-Server/.../index_network.html': 1,\n",
       " 'GET SN-SZY-Server/.../index_wechat.html': 326,\n",
       " 'GET SN-SZY-Server/.../init.do': 50880,\n",
       " 'GET SN-SZY-Server/.../initList.do': 9877,\n",
       " 'GET SN-SZY-Server/.../initNotice.do': 17971,\n",
       " 'GET SN-SZY-Server/.../outFeeDetail.do': 1221,\n",
       " 'GET SN-SZY-Server/.../outFeeList.do': 4004,\n",
       " 'GET SN-SZY-Server/.../registeNotice.do': 74,\n",
       " 'GET SN-SZY-Server/.../registerDetail.html': 533,\n",
       " 'GET SN-SZY-Server/.../registerGuide.html': 349,\n",
       " 'GET SN-SZY-Server/.../registerList.do': 4068,\n",
       " 'GET SN-SZY-Server/.../registerNotice.html': 447,\n",
       " 'GET SN-SZY-Server/.../selectByDoctorId.do': 2576,\n",
       " 'GET SN-SZY-Server/.../selectInfoById.do': 484,\n",
       " 'GET SN-SZY-Server/.../sheetNotice.html': 90,\n",
       " 'GET SN-SZY-Server/.../toBindCard.do': 1361,\n",
       " 'GET SN-SZY-Server/.../toGetUserInfo.do': 339,\n",
       " 'GET SN-SZY-Server/.../toRegister.do': 843,\n",
       " 'GET SN-SZY-Server/.../toReturnSelectPatient.do': 1106,\n",
       " 'GET SN-SZY-Server/.../toSelectAllPatient.do': 1324,\n",
       " 'GET SN-SZY-Server/.../toTargetUrl.do': 835,\n",
       " 'GET SN-SZY-Server/.../update.do': 1,\n",
       " 'GET SN-SZY-Server/.../westDept.do': 14047,\n",
       " 'GET index.php': 4,\n",
       " 'GET schedule/.../init.do': 1,\n",
       " 'GET user/.../init.do': 321,\n",
       " 'HEAD /.../': 1,\n",
       " 'HEAD SN-SZY-Server/.../init.do': 160,\n",
       " 'HEAD SN-SZY-Server/.../initNotice.do': 40,\n",
       " 'HEAD SN-SZY-Server/.../registerList.do': 40,\n",
       " 'POST /.../bind.do': 663,\n",
       " 'POST /.../bindCard.do': 635,\n",
       " 'POST /.../check.do': 999,\n",
       " 'POST /.../doRegister.do': 1138,\n",
       " 'POST /.../getCode.do': 688,\n",
       " 'POST /.../init.do': 9,\n",
       " 'POST /.../logout.do': 13,\n",
       " 'POST /.../register.do': 741,\n",
       " 'POST /.../sendCode.do': 1188,\n",
       " 'POST SN-SZY-Server/.../cancelRegister.do': 346,\n",
       " 'POST SN-SZY-Server/.../checkIdCard.do': 1049,\n",
       " 'POST SN-SZY-Server/.../coreServlet': 22345,\n",
       " 'POST SN-SZY-Server/.../delete.do': 18,\n",
       " 'POST SN-SZY-Server/.../doRegister.do': 750,\n",
       " 'POST SN-SZY-Server/.../toBindCard.do': 21,\n",
       " 'POST SN-SZY-Server/.../update.do': 22,\n",
       " 'POST index.php': 4}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_url_list_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13385, 20, 32)\n"
     ]
    }
   ],
   "source": [
    "data = operations_to_sequence(user_behavior_dict)\n",
    "print (data.shape) #数据编码，我就是快，数据量大640倍，还是快。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'27.204.15.164'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-dd46f41a8d6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_behavior_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'27.204.15.164'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'urls'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: '27.204.15.164'"
     ]
    }
   ],
   "source": [
    "len(user_behavior_dict['27.204.15.164'][2]['urls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 旧版的数据转换\n",
    "# def label_operations(all_url_dict_list):\n",
    "#     operation_label = np.zeros(len(all_url_dict_list)) # 先按照0 1 2 3，一维数组排序\n",
    "#     ip_operation_index = 0\n",
    "#     for ip_operations in all_url_dict_list: #对于每小段窗口，以ip归类的urls集合\n",
    "#         operation_label[ip_operation_index] = get_operation_label(ip_operations['ip'],ip_operations['time'])\n",
    "#         ip_operation_index = ip_operation_index + 1\n",
    "        \n",
    "#     #转化为one-hot编码的label\n",
    "#     return operation_label\n",
    "\n",
    "\n",
    "def label_operations(user_behavior_dict):\n",
    "    #计算这个dict中有多少段操作\n",
    "    n_op_details = 0\n",
    "    for x in user_behavior_dict.keys():\n",
    "        n_op_details += len(user_behavior_dict[x])\n",
    "        \n",
    "    operation_labels = np.zeros(n_op_details) # 先按照0 1 2 3，一维数组排序\n",
    "    operation_coverages = np.zeros(n_op_details) # 先按照0 1 2 3，一维数组排序\n",
    "    ip_operation_index = 0\n",
    "    for ip in user_behavior_dict.keys(): #对于每个ip,得到op_detail列表\n",
    "        for op_index in range(len(user_behavior_dict[ip])): #对于每一组urls操作，得到其index \n",
    "            operation_labels[ip_operation_index] = get_operation_label(ip)\n",
    "            operation_coverages[ip_operation_index] = labels_dict[ip]['coverage']\n",
    "            ip_operation_index += 1\n",
    "            \n",
    "    return operation_labels, operation_coverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13385,)\n"
     ]
    }
   ],
   "source": [
    "# tmd为啥这么慢，为啥这么慢，为啥这么慢啊!!!!!!\n",
    "labels, coverages = label_operations(user_behavior_dict)\n",
    "print (labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3855"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labels==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #labels\n",
    "# b = np.argsort(labels)\n",
    "# b = b.tolist()\n",
    "# b.reverse()\n",
    "# for x in b:\n",
    "#     if labels[x] > 0.9 and labels[x] < 1:\n",
    "#         #ip = iPAccessInfo.all_url_dict_list[x]['ip']\n",
    "#         print(iPAccessInfo.all_url_dict_list[x])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5361"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labels==0).sum() #验证每个类别的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#网址embedding表示，应该不需要进行正规化吧\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# #由于时序序列数据，是（？，时间长度，数据长度）的，所以应该执行一个reshape\n",
    "# X = scaler.fit_transform(data.reshape([-1,20*32]))\n",
    "# X = X.reshape([-1,20,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义保存数据的类\n",
    "import numpy as np\n",
    "\n",
    "#定义类\n",
    "class IPAccessData(object):\n",
    "    def __init__(self, X, y, coverage):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.coverage = coverage\n",
    "#         self.ip_dict = ip_dict\n",
    "#         self.ip_reserve_list = ip_reserve_list\n",
    "#         self.data_scaler = data_scaler\n",
    "\n",
    "# 保存文件为pkl\n",
    "import pickle\n",
    "\n",
    "iPAccessData = IPAccessData(data,labels,coverages)\n",
    "fp = open('iPAccessData_count.pkl','wb',True)\n",
    "pickle.dump(iPAccessData, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
